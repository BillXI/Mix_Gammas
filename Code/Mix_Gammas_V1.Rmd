---
title: "Mix_Gammas_V1"
author: "Xi Chen"
date: "June 11, 2016"
output: pdf_document
---
## Read in the gammamixEM2.R file
```{r setup, echo=FALSE}
source("./Code/gammamixEM2.R")
set.seed(518)
library("mixtools")
library("MASS")
```

## Consider 12 settings and for each of the 12 conditions, do the follwoing:
Number of samples: B
Sample size: n

```{r}
sample.size = 5
# sample.size = 5000
n.iter = c(100, 250, 500)

parameters <- function(){
        conditions <- list()
        # Condition 1
        conditions[["C1"]] <- data.frame(c(2,5),c(3,4),c(0.5,0.5))
        colnames(conditions[["C1"]]) <- c("a", "b", "l")
        # Condition 2
        conditions[["C2"]] <- data.frame(c(2,5),c(3,4),c(0.2,0.8))
        colnames(conditions[["C2"]]) <- c("a", "b", "l")
        # Condition 3
        conditions[["C3"]] <- data.frame(c(1,10),c(1,1),c(0.5,0.5))
        colnames(conditions[["C3"]]) <- c("a", "b", "l")
        # Condition 4
        conditions[["C4"]] <- data.frame(c(1,10),c(1,1),c(0.2,0.8))
        colnames(conditions[["C4"]]) <- c("a", "b", "l")
        # Condition 5
        conditions[["C5"]] <- data.frame(c(2,30),c(3,2),c(0.5,0.5))
        colnames(conditions[["C5"]]) <- c("a", "b", "l")
        # Condition 6
        conditions[["C6"]] <- data.frame(c(2,30),c(3,2),c(0.2,0.8))
        colnames(conditions[["C6"]]) <- c("a", "b", "l")
        # Condition 7
        conditions[["C7"]] <- data.frame(c(2,5,6),c(3,5,7),c(1/3,1/3,1/3))
        colnames(conditions[["C7"]]) <- c("a", "b", "l")
        # Condition 8
        conditions[["C8"]] <- data.frame(c(2,5,6),c(3,5,7),c(0.2,0.3,0.5))
        colnames(conditions[["C8"]]) <- c("a", "b", "l")
        # Condition 9
        conditions[["C9"]] <- data.frame(c(1,20,50),c(2,4,3),c(0.2,0.3,0.5))
        colnames(conditions[["C9"]]) <- c("a", "b", "l")
        # Condition 10
        conditions[["C10"]] <- data.frame(c(1,20,50),c(2,4,3),c(0.2,0.3,0.5))
        colnames(conditions[["C10"]]) <- c("a", "b", "l")
        # Condition 11
        conditions[["C11"]] <- data.frame(c(2,50,180),c(1,2,3),c(0.2,0.3,0.5))
        colnames(conditions[["C11"]]) <- c("a", "b", "l")
        # Condition 12
        conditions[["C12"]] <- data.frame(c(2,50,180),c(1,2,3),c(0.2,0.3,0.5))
        colnames(conditions[["C12"]]) <- c("a", "b", "l")
        return(conditions)
}
conditions <- parameters()

```

## Generates Sample:
We are using the rate not beta, which rate = 1/beta

```{r}
set.seed(111)
sample.generation <- function(sample.size, parameters){
        samples <- apply(parameters, 1, function(i){rgamma(sample.size* i[3], shape = i[1], scale = i[2])
        })
        return(unlist(samples))
}
sample.generation(10, conditions[["C12"]])

```

## Estimation:
For each set of samples, estimate the mixture-of-gammas model using 4 different stragegies:

### Strategies 1
Specify the starting values in gammamixEM2 using the parameter values for the simulation.

```{r}
estimation1.f <- function(dat, para){
        a <- para$a
        b <- para$b
        l <- para$l
        numOfDist <- nrow(para)
        output1 <- lapply(dat, function{
                gammamixEM2(x, lambda = l, alpha = a, beta = b, k = numOfDist,)
        })
        return(output1)
}
```

### Strategies 2
Do not specify starting values for any of the parameters in gammamixEM2. Run the algorithm 10 times and retain the output that has the best log-likelihood value; i.e. the fit that has the largest log-likelihood value.
```{r}
estimation2.f <- function(dat){
        numOfDist <- nrow(para)
        output1 <- lapply(dat, function{
                gammamixEM2(x, k = numOfDist)
        })
        return(output1)
}
```
### Strategies 3
* Transform simulated data by taking the cub root, using normalmixEM to classify each observation to a component, which will effectively partition the simulated data into k groups. 

* Do this classfication
* Meeting June 22, 16: 
   * The fitdist() function from tent's code might not stable, so we decided to use the gamma.nr(), used it to estimate the parameter after classification and transform back to gamma with ^3. 
```{r}
estimation2.f <- function(dat){
        datCubeRoot <- dat^(1/3)
        numOfDist <- nrow(para)
        output1 <- lapply(datCubeRoot, function{
                classification < - normalmixEM(x, k = numOfDist)
        })
        return(output1)
}
```
### Strategies 4

```{r}

```

